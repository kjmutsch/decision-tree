{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0271551-67c8-4d2e-9864-eb8ee749a8b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Decision Tree in Python from Scratch\n",
    "\n",
    "<p>This project is a passion project in my pursuit of machine learning knowledge. I felt to understand decision trees the best, I should make my own from scratch. I'm using the CART algorithm and gini impurity to build my tree.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8256be0-5afd-481b-bd54-b1aa0d565bba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77a652ae-247a-4381-9de9-7b08d625b593",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# attributes: color, diameter, \n",
    "# label\n",
    "training_data = [\n",
    "  ['Green', 3, 'Apple'],\n",
    "  ['Yellow', 4, 'Apple'],\n",
    "  ['Red', 1, 'Grape'],\n",
    "  ['Red', 1, 'Grape'],\n",
    "  ['Yellow', 3, 'Lemon'],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27687189-9cb2-4cc5-b3f4-37732c004dc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Utility Functions\n",
    "\n",
    "<p>The general utility functions needed for a decision tree are as follows:</p>\n",
    "1. Gini Impurity Calculation for measuring the quality of a split\n",
    "2. Entropy/Information Gain Calculation to determine best split\n",
    "3. Data Splitting split dataset into features and theshold\n",
    "4. Tree Node Creation to create nodes and leaves\n",
    "5. Tree Building to recursively build the tree\n",
    "6. Prediction to make predicitons using the constructed tree\n",
    "7. Accuracy to test how good our model is on test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "028f23c3-b59d-464a-ad62-5c91baed86c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Gini Impurity calculates the impurity or how likely it is that a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the set.\n",
    "# y is the list of labels, in our small example it would be ['Apple', 'Apple', 'Grape', 'Grape', 'Lemon']\n",
    "def gini_impurity(y):\n",
    "  \"\"\"Calculate the Gini Impurity for a list of class labels\"\"\"\n",
    "  if not y or len(y) == 0:\n",
    "    return 0.0\n",
    "  from collections import Counter\n",
    "  counts = Counter(y)\n",
    "  # in our mini example it would look like Counter({Apple: 2, Grape: 2, Lemon: 1})\n",
    "  impurity = 1\n",
    "  total = len(y) # 3\n",
    "  for label in counts:\n",
    "    probability_of_label = counts[label] / total\n",
    "    # for apple = 0.4\n",
    "    # for grape = 0.4\n",
    "    # for lemon = 0.2\n",
    "    # then square them and subract from 1\n",
    "    impurity -= probability_of_label ** 2\n",
    "  return impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3266d626-57e2-45dd-b201-0f51ac522880",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Information Gain where parent_y is the parent node, left_y is the left child node, right_y is the right child node\n",
    "def information_gain(parent_y, left_y, right_y):\n",
    "  \"\"\"Calculate the Information Gain of a split\"\"\"\n",
    "  p = len(left_y) / len(parent_y)\n",
    "  return gini_impurity(parent_y) - p * gini_impurity(left_y) - (1 - p) * gini_impurity(right_y)\n",
    "  # returns the gini impurity of the parent (0.65) minus the probability of the left child (4/5) * the left child's gini impurity (0.625) minus the probability of the right child (1/5) * the right child's gini impurity (0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31363369-15de-461f-8930-e3911fedffcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Data splitting where X are the features, y are the labels, feature_index is the index of the feature to split on, threshold is the value of the feature to split on\n",
    "def split_dataset(X, y, feature_index, threshold):\n",
    "  \"\"\"Split the dataset based on a feature and threshold\"\"\"\n",
    "  left_X, right_X = [],[]\n",
    "  left_y, right_y = [],[]\n",
    "  for i in range(len(X)):\n",
    "    if X[i][feature_index] <= threshold:\n",
    "      left_X.append(X[i])\n",
    "      left_y.append(y[i])\n",
    "    else:\n",
    "      right_X.append(X[i])\n",
    "      right_y.append(y[i])\n",
    "  return left_X, right_X, left_y, right_y\n",
    "\n",
    "# in our micro-example we'd have the left child with [['Green', 3], ['Red', 1], ['Red', 1], ['Yellow', 3]] with labels ['Apple', 'Grape', 'Grape', 'Lemon'] and the right child would have [['Yellow', 4]] with label(s) ['Apple'] and geni impurity after the fact would be 0.625 for the left and 0 for the right child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7338fa8c-d7fb-4ea4-bbab-e788a2178324",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def find_best_split(X, y):\n",
    "  \"\"\"Find the best feature and threshold to split the data.\"\"\"\n",
    "  best_gain = 0\n",
    "  best_feature_index = None\n",
    "  best_threshold = None\n",
    "  best_splits = None\n",
    "\n",
    "  n_features = len(X[0]) # number of features\n",
    "\n",
    "  for feature_index in range(n_features):\n",
    "    thresholds = set([x[feature_index] for x in X])\n",
    "    for threshold in thresholds:\n",
    "      left_X, right_X, left_y, right_y = split_dataset(X, y, feature_index, threshold)\n",
    "      if not left_X or not right_X:\n",
    "        continue\n",
    "      gain = information_gain(y, left_y, right_y)\n",
    "      if gain > best_gain:\n",
    "        best_gain = gain\n",
    "        best_feature_index = feature_index\n",
    "        best_threshold = threshold\n",
    "        best_splits = (left_X, right_X, left_y, right_y)\n",
    "  return best_feature_index, best_threshold, best_gain, best_splits\n",
    "\n",
    "  # feature index and threshold are used when we split the data\n",
    "  # best_gain is for testing and tracking effectiveness of split\n",
    "  # best_splits is for when we build the tree\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64113435-734b-41c9-ac52-fc9df011a669",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Tree Node Creation\n",
    "class TreeNode:\n",
    "  def __init__(self, feature_index=None, threshold=None, left=None, right=None, *, value=None):\n",
    "    self.feature_index = feature_index\n",
    "    self.threshold = threshold\n",
    "    self.left = left # left node\n",
    "    self.right = right # right node\n",
    "    self.value = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e081ca38-0ec5-4884-acc0-e7902aa7cfbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Tree Building\n",
    "def build_tree(X, y, depth=0, max_depth=10):\n",
    "  \"\"\"Recursively build decision tree\"\"\"\n",
    "  # if we reached the max depth or the node is the last in the set, then we set the leaf value as the most common value in the current set of labels\n",
    "  if depth == max_depth or len(set(y)) == 1:\n",
    "    leaf_value = max(set(y), key=list(y).count) # finds the element in the set y that has the highest count in the list y, key argument specifies a function to apply to each element before making a comparison. So we check what element has the most occurrences first (example 'Apple' could have 2)\n",
    "    return TreeNode(value=leaf_value)\n",
    "  \n",
    "  # find the best split\n",
    "  best_feature_index, best_threshold, best_gain, best_splits = find_best_split(X, y)\n",
    "\n",
    "  # if no split, make it a leaf\n",
    "  if best_gain == 0:\n",
    "    leaf_value = max(set(y), key=list(y).count)\n",
    "    return TreeNode(value=leaf_value)\n",
    "  \n",
    "  # create child nodes of this node\n",
    "  left_X, right_X, left_y, right_y = best_splits\n",
    "  left_child = build_tree(left_X, left_y, depth + 1, max_depth)\n",
    "  right_child = build_tree(right_X, right_y, depth + 1, max_depth)\n",
    "\n",
    "  return TreeNode(feature_index=best_feature_index, threshold=best_threshold, left=left_child, right=right_child)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff9b8d27-9734-4ca2-86d7-eaeb975903f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def print_tree(node, depth=0):\n",
    "  if node.value is not None:\n",
    "    print(f\"{'  ' * depth}Predict: {node.value}\")\n",
    "  else:\n",
    "    print(f\"{'  ' * depth}[X{node.feature_index} <= {node.threshold}]\")\n",
    "    print_tree(node.left, depth + 1)\n",
    "    print_tree(node.right, depth + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18cb4e77-7790-44d5-81f2-7b0255e00031",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X1 <= 1]\n  Predict: Grape\n  [X1 <= 3]\n    [X0 <= Green]\n      Predict: Apple\n      Predict: Lemon\n    Predict: Apple\n"
     ]
    }
   ],
   "source": [
    "# Test with our small example of data\n",
    "X = [row[:2] for row in training_data]  # Features\n",
    "y = [row[2] for row in training_data]   # Labels\n",
    "# X are the features and they look like this:\n",
    "\"\"\" [['Green', 3], ['Yellow', 4], ['Red', 1], ['Red', 1], ['Yellow', 3]] \"\"\"\n",
    "# y are the labels and they look like this:\n",
    "\"\"\" ['Apple', 'Apple', 'Grape', 'Grape', 'Lemon'] \"\"\"\n",
    "\n",
    "# Build the tree\n",
    "tree = build_tree(X, y, max_depth=3)\n",
    "\n",
    "# Print the tree\n",
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "622c765b-69e3-42bc-bc77-8ec4edfd3432",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(tree, X_test, y_test):\n",
    "    \"\"\"Calculate the accuracy of the decision tree on the test data.\"\"\"\n",
    "    correct_predictions = 0\n",
    "    for i in range(len(X_test)):\n",
    "        if predict(tree, X_test[i]) == y_test[i]:\n",
    "            correct_predictions += 1\n",
    "    return correct_predictions / len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d3f33cf-0fa2-49e8-81c2-50717cd826a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def predict(tree, X):\n",
    "    \"\"\"Make a prediction for a single instance X using the decision tree.\"\"\"\n",
    "    if tree.value is not None:\n",
    "        return tree.value\n",
    "    feature_value = X[tree.feature_index]\n",
    "    print(feature_value, tree.threshold)\n",
    "    if feature_value <= tree.threshold:\n",
    "        return predict(tree.left, X)\n",
    "    else:\n",
    "        return predict(tree.right, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b6b8ac0-dba1-4a5a-a079-e7506f749576",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  ['Apple', 'Apple', 'Grape', 'Lemon']\nAccuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_data = [\n",
    "  ['Green', 3, 'Apple'],\n",
    "  ['Yellow', 4, 'Apple'],\n",
    "  ['Red', 1, 'Grape'],\n",
    "  ['Yellow', 3, 'Lemon'],\n",
    "]\n",
    "X_test = [row[:2] for row in test_data]  # Features\n",
    "y_test = [row[2] for row in test_data]   # Labels\n",
    "\n",
    "# Make a prediction and test the accuracy of tree\n",
    "predictions = [predict(tree, x) for x in X_test]\n",
    "print(\"Predictions: \", predictions)\n",
    "\n",
    "accur = accuracy(tree, X_test, y_test)\n",
    "print(\"Accuracy:\", accur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80bd2d7f-e462-47de-a4d1-39e30e4c5098",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Use a the iris dataset to test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9db30365-1ec9-488d-9c93-61970888b5c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target # features and labels\n",
    "\n",
    "print(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76a67046-2af2-4ebf-808c-683024fdb897",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X2 <= 1.9]\n  Predict: 0\n  [X2 <= 4.7]\n    [X3 <= 1.6]\n      Predict: 1\n      Predict: 2\n    [X3 <= 1.7]\n      Predict: 1\n      Predict: 2\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # random state is so we can reproduce the same split, 20% of the data is used for testing\n",
    "\n",
    "iris_tree = build_tree(X_train.tolist(), y_train.tolist(), max_depth=3)\n",
    "print_tree(iris_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5766905-d63c-4c79-8b1b-2eacba94a77b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.7 1.9\n4.7 4.7\n1.2 1.6\n1.7 1.9\n6.9 1.9\n6.9 4.7\n2.3 1.7\n4.5 1.9\n4.5 4.7\n1.5 1.6\n4.8 1.9\n4.8 4.7\n1.4 1.7\n1.5 1.9\n3.6 1.9\n3.6 4.7\n1.3 1.6\n5.1 1.9\n5.1 4.7\n2.3 1.7\n4.5 1.9\n4.5 4.7\n1.5 1.6\n3.9 1.9\n3.9 4.7\n1.2 1.6\n5.1 1.9\n5.1 4.7\n2.0 1.7\n1.4 1.9\n1.3 1.9\n1.5 1.9\n1.5 1.9\n4.7 1.9\n4.7 4.7\n1.6 1.6\n5.8 1.9\n5.8 4.7\n2.2 1.7\n3.9 1.9\n3.9 4.7\n1.1 1.6\n4.5 1.9\n4.5 4.7\n1.3 1.6\n5.6 1.9\n5.6 4.7\n2.2 1.7\n1.6 1.9\n4.9 1.9\n4.9 4.7\n1.8 1.7\n1.6 1.9\n5.6 1.9\n5.6 4.7\n2.1 1.7\n6.4 1.9\n6.4 4.7\n2.0 1.7\n5.2 1.9\n5.2 4.7\n2.3 1.7\n5.8 1.9\n5.8 4.7\n1.8 1.7\n5.9 1.9\n5.9 4.7\n2.3 1.7\n1.4 1.9\n1.6 1.9\nAccuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the tree\n",
    "# Calculate accuracy on the test data\n",
    "acc = accuracy(iris_tree, X_test.tolist(), y_test.tolist())\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af3c0345-031a-45f3-b0e7-9fa71a1d7154",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Tests\n",
    "\n",
    "#### Tests with simple dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73992a02-7d50-43a6-a0f5-23fd4cea297a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8 1.3\n1.2 1.3\ntest_simple_dataset passed\n"
     ]
    }
   ],
   "source": [
    "def test_simple_dataset():\n",
    "  # Simple dataset\n",
    "  training_data = [\n",
    "      [2.7, 2.5, 'A'],\n",
    "      [1.3, 1.5, 'B'],\n",
    "      [3.1, 3.0, 'A'],\n",
    "      [1.1, 1.2, 'B'],\n",
    "  ]\n",
    "  \n",
    "  X = [row[:2] for row in training_data]  # Features\n",
    "  y = [row[2] for row in training_data]   # Labels\n",
    "  \n",
    "  # Build the tree\n",
    "  tree = build_tree(X, y, max_depth=3)\n",
    "  \n",
    "  # Test predictions\n",
    "  test_data = [\n",
    "      [2.8, 2.6],  # Should be 'A'\n",
    "      [1.2, 1.3],  # Should be 'B'\n",
    "  ]\n",
    "  \n",
    "  predictions = [predict(tree, x) for x in test_data]\n",
    "  expected = ['A', 'B']\n",
    "  \n",
    "  assert predictions == expected, f\"Expected {expected}, but got {predictions}\"\n",
    "  print(\"test_simple_dataset passed\")\n",
    "\n",
    "test_simple_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87762398-085e-4eb8-a85d-04f490c330b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Test with Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1e0cbc2-0f46-4f29-8e8d-d1637aa1c77d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.7 1.9\n4.7 4.7\n1.2 1.6\n1.7 1.9\n6.9 1.9\n6.9 4.7\n2.3 1.7\n4.5 1.9\n4.5 4.7\n1.5 1.6\n4.8 1.9\n4.8 4.7\n1.4 1.7\n1.5 1.9\n3.6 1.9\n3.6 4.7\n1.3 1.6\n5.1 1.9\n5.1 4.7\n2.3 1.7\n4.5 1.9\n4.5 4.7\n1.5 1.6\n3.9 1.9\n3.9 4.7\n1.2 1.6\n5.1 1.9\n5.1 4.7\n2.0 1.7\n1.4 1.9\n1.3 1.9\n1.5 1.9\n1.5 1.9\n4.7 1.9\n4.7 4.7\n1.6 1.6\n5.8 1.9\n5.8 4.7\n2.2 1.7\n3.9 1.9\n3.9 4.7\n1.1 1.6\n4.5 1.9\n4.5 4.7\n1.3 1.6\n5.6 1.9\n5.6 4.7\n2.2 1.7\n1.6 1.9\n4.9 1.9\n4.9 4.7\n1.8 1.7\n1.6 1.9\n5.6 1.9\n5.6 4.7\n2.1 1.7\n6.4 1.9\n6.4 4.7\n2.0 1.7\n5.2 1.9\n5.2 4.7\n2.3 1.7\n5.8 1.9\n5.8 4.7\n1.8 1.7\n5.9 1.9\n5.9 4.7\n2.3 1.7\n1.4 1.9\n1.6 1.9\ntest_iris_dataset passed\n"
     ]
    }
   ],
   "source": [
    "def test_iris_dataset():\n",
    "  from sklearn.datasets import load_iris\n",
    "  from sklearn.model_selection import train_test_split\n",
    "\n",
    "  # Load the iris dataset\n",
    "  iris = load_iris()\n",
    "  X, y = iris.data, iris.target\n",
    "\n",
    "  # Split the dataset into training and test sets\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "  # Build the tree using the training data\n",
    "  tree = build_tree(X_train.tolist(), y_train.tolist(), max_depth=3)\n",
    "\n",
    "  # Calculate accuracy on the test data\n",
    "  acc = accuracy(tree, X_test.tolist(), y_test.tolist())\n",
    "  \n",
    "  assert acc > 0.7, f\"Expected accuracy > 0.7, but got {acc}\"\n",
    "  print(\"test_iris_dataset passed\")\n",
    "\n",
    "test_iris_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6afbc16b-72ef-4757-944b-4076403c0f37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Test of single class (all labeled 'A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59ac4f2a-8088-4bad-9216-b2a5c74c1865",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_edge_cases passed\n"
     ]
    }
   ],
   "source": [
    "def test_edge_cases():\n",
    "  # Dataset with only one class\n",
    "  training_data = [\n",
    "      [2.7, 2.5, 'A'],\n",
    "      [3.1, 3.0, 'A'],\n",
    "      [2.9, 2.8, 'A'],\n",
    "  ]\n",
    "  \n",
    "  X = [row[:2] for row in training_data]  # Features\n",
    "  y = [row[2] for row in training_data]   # Labels\n",
    "  \n",
    "  # Build the tree\n",
    "  tree = build_tree(X, y, max_depth=3)\n",
    "  \n",
    "  # Test predictions\n",
    "  test_data = [\n",
    "      [2.8, 2.6],  # Should be 'A'\n",
    "      [3.0, 2.9],  # Should be 'A'\n",
    "  ]\n",
    "  \n",
    "  predictions = [predict(tree, x) for x in test_data]\n",
    "  expected = ['A', 'A']\n",
    "  \n",
    "  assert predictions == expected, f\"Expected {expected}, but got {predictions}\"\n",
    "  print(\"test_edge_cases passed\")\n",
    "\n",
    "test_edge_cases()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1dce723d-2982-41f4-a519-305d3d275f28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Test accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6b19e38-56ad-4efb-8b38-300dfc3f1924",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8 1.3\n1.2 1.3\n3.0 1.3\n1.0 1.3\ntest_accuracy_calculation passed\n"
     ]
    }
   ],
   "source": [
    "def test_accuracy_calculation():\n",
    "  # Simple dataset\n",
    "  training_data = [\n",
    "      [2.7, 2.5, 'A'],\n",
    "      [1.3, 1.5, 'B'],\n",
    "      [3.1, 3.0, 'A'],\n",
    "      [1.1, 1.2, 'B'],\n",
    "  ]\n",
    "  \n",
    "  X = [row[:2] for row in training_data]  # Features\n",
    "  y = [row[2] for row in training_data]   # Labels\n",
    "  \n",
    "  # Build the tree\n",
    "  tree = build_tree(X, y, max_depth=3)\n",
    "  \n",
    "  # Test data\n",
    "  test_data = [\n",
    "      [2.8, 2.6, 'A'],\n",
    "      [1.2, 1.3, 'B'],\n",
    "      [3.0, 2.9, 'A'],\n",
    "      [1.0, 1.1, 'B'],\n",
    "  ]\n",
    "  \n",
    "  X_test = [row[:2] for row in test_data]  # Features\n",
    "  y_test = [row[2] for row in test_data]   # Labels\n",
    "  \n",
    "  # Calculate accuracy\n",
    "  acc = accuracy(tree, X_test, y_test)\n",
    "  \n",
    "  assert acc == 1.0, f\"Expected accuracy 1.0, but got {acc}\"\n",
    "  print(\"test_accuracy_calculation passed\")\n",
    "\n",
    "test_accuracy_calculation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4dc95142-1cca-4440-afb2-5e3b828ac2f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8 1.3\n1.2 1.3\ntest_simple_dataset passed\n4.7 1.9\n4.7 4.7\n1.2 1.6\n1.7 1.9\n6.9 1.9\n6.9 4.7\n2.3 1.7\n4.5 1.9\n4.5 4.7\n1.5 1.6\n4.8 1.9\n4.8 4.7\n1.4 1.7\n1.5 1.9\n3.6 1.9\n3.6 4.7\n1.3 1.6\n5.1 1.9\n5.1 4.7\n2.3 1.7\n4.5 1.9\n4.5 4.7\n1.5 1.6\n3.9 1.9\n3.9 4.7\n1.2 1.6\n5.1 1.9\n5.1 4.7\n2.0 1.7\n1.4 1.9\n1.3 1.9\n1.5 1.9\n1.5 1.9\n4.7 1.9\n4.7 4.7\n1.6 1.6\n5.8 1.9\n5.8 4.7\n2.2 1.7\n3.9 1.9\n3.9 4.7\n1.1 1.6\n4.5 1.9\n4.5 4.7\n1.3 1.6\n5.6 1.9\n5.6 4.7\n2.2 1.7\n1.6 1.9\n4.9 1.9\n4.9 4.7\n1.8 1.7\n1.6 1.9\n5.6 1.9\n5.6 4.7\n2.1 1.7\n6.4 1.9\n6.4 4.7\n2.0 1.7\n5.2 1.9\n5.2 4.7\n2.3 1.7\n5.8 1.9\n5.8 4.7\n1.8 1.7\n5.9 1.9\n5.9 4.7\n2.3 1.7\n1.4 1.9\n1.6 1.9\ntest_iris_dataset passed\ntest_edge_cases passed\n2.8 1.3\n1.2 1.3\n3.0 1.3\n1.0 1.3\ntest_accuracy_calculation passed\nAll tests passed\n"
     ]
    }
   ],
   "source": [
    "def run_all_tests():\n",
    "  test_simple_dataset()\n",
    "  test_iris_dataset()\n",
    "  test_edge_cases()\n",
    "  test_accuracy_calculation()\n",
    "  print(\"All tests passed\")\n",
    "\n",
    "run_all_tests()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Decision Tree from Scratch",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
