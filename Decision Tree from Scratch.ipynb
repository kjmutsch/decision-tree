{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0271551-67c8-4d2e-9864-eb8ee749a8b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Decision Tree in Python from Scratch\n",
    "\n",
    "<p>This project is a passion project in my pursuit of machine learning knowledge. I felt to understand decision trees the best, I should make my own from scratch. I'm using the ___ algorithm and gini impurity (instead of entropy)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8256be0-5afd-481b-bd54-b1aa0d565bba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77a652ae-247a-4381-9de9-7b08d625b593",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# attributes: color, diameter, \n",
    "# label\n",
    "training_data = [\n",
    "  ['Green', 3, 'Apple'],\n",
    "  ['Yellow', 4, 'Apple'],\n",
    "  ['Red', 1, 'Grape'],\n",
    "  ['Red', 1, 'Grape'],\n",
    "  ['Yellow', 3, 'Lemon'],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27687189-9cb2-4cc5-b3f4-37732c004dc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Utility Functions\n",
    "\n",
    "<p>The general utility functions needed for a decision tree are as follows:</p>\n",
    "1. Gini Impurity Calculation for measuring the quality of a split\n",
    "2. Entropy/Information Gain Calculation to determine best split\n",
    "3. Data Splitting split dataset into features and theshold\n",
    "4. Tree Node Creation to create nodes and leaves\n",
    "5. Tree Building to recursively build the tree\n",
    "6. Prediction to make predicitons using the constructed tree\n",
    "7. Accuracy to test how good our model is on test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "028f23c3-b59d-464a-ad62-5c91baed86c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Gini Impurity calculates the impurity or how likely it is that a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the set.\n",
    "# y is the list of labels, in our small example it would be ['Apple', 'Apple', 'Grape', 'Grape', 'Lemon']\n",
    "def gini_impurity(y):\n",
    "  \"\"\"Calculate the Gini Impurity for a list of class labels\"\"\"\n",
    "  if not y or len(y) == 0:\n",
    "    return 0.0\n",
    "  from collections import Counter\n",
    "  counts = Counter(y)\n",
    "  # in our mini example it would look like Counter({Apple: 2, Grape: 2, Lemon: 1})\n",
    "  impurity = 1\n",
    "  total = len(y) # 3\n",
    "  for label in counts:\n",
    "    probability_of_label = counts[label] / total\n",
    "    # for apple = 0.4\n",
    "    # for grape = 0.4\n",
    "    # for lemon = 0.2\n",
    "    # then square them and subract from 1\n",
    "    impurity -= probability_of_label ** 2\n",
    "  return impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3266d626-57e2-45dd-b201-0f51ac522880",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Information Gain where parent_y is the parent node, left_y is the left child node, right_y is the right child node\n",
    "def information_gain(parent_y, left_y, right_y):\n",
    "  \"\"\"Calculate the Information Gain of a split\"\"\"\n",
    "  p = len(left_y) / len(parent_y)\n",
    "  return gini_impurity(parent_y) - p * gini_impurity(left_y) - (1 - p) * gini_impurity(right_y)\n",
    "  # returns the gini impurity of the parent (0.65) minus the probability of the left child (4/5) * the left child's gini impurity (0.625) minus the probability of the right child (1/5) * the right child's gini impurity (0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31363369-15de-461f-8930-e3911fedffcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Data splitting where X are the features, y are the labels, feature_index is the index of the feature to split on, threshold is the value of the feature to split on\n",
    "def split_dataset(X, y, feature_index, threshold):\n",
    "  \"\"\"Split the dataset based on a feature and threshold\"\"\"\n",
    "  left_X, right_X = [],[]\n",
    "  left_y, right_y = [],[]\n",
    "  for i in range(len(X)):\n",
    "    if X[i][feature_index] <= threshold:\n",
    "      left_X.append(X[i])\n",
    "      left_y.append(y[i])\n",
    "    else:\n",
    "      right_X.append(X[i])\n",
    "      right_y.append(y[i])\n",
    "  return left_X, right_X, left_y, right_y\n",
    "\n",
    "# in our micro-example we'd have the left child with [['Green', 3], ['Red', 1], ['Red', 1], ['Yellow', 3]] with labels ['Apple', 'Grape', 'Grape', 'Lemon'] and the right child would have [['Yellow', 4]] with label(s) ['Apple'] and geni impurity after the fact would be 0.625 for the left and 0 for the right child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7338fa8c-d7fb-4ea4-bbab-e788a2178324",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def find_best_split(X, y):\n",
    "  \"\"\"Find the best feature and threshold to split the data.\"\"\"\n",
    "  best_gain = 0\n",
    "  best_feature_index = None\n",
    "  best_threshold = None\n",
    "  best_splits = None\n",
    "\n",
    "  n_features = len(X[0]) # number of features\n",
    "\n",
    "  for feature_index in range(n_features):\n",
    "    thresholds = set([x[feature_index] for x in X])\n",
    "    for threshold in thresholds:\n",
    "      left_X, right_X, left_y, right_y = split_dataset(X, y, feature_index, threshold)\n",
    "      if not left_X or not right_X:\n",
    "        continue\n",
    "      gain = information_gain(y, left_y, right_y)\n",
    "      if gain > best_gain:\n",
    "        best_gain = gain\n",
    "        best_feature_index = feature_index\n",
    "        best_threshold = threshold\n",
    "        best_splits = (left_X, right_X, left_y, right_y)\n",
    "  return best_feature_index, best_threshold, best_gain, best_splits\n",
    "\n",
    "  # feature index and threshold are used when we split the data\n",
    "  # best_gain is for testing and tracking effectiveness of split\n",
    "  # best_splits is for when we build the tree\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64113435-734b-41c9-ac52-fc9df011a669",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Tree Node Creation\n",
    "class TreeNode:\n",
    "  def __init__(self, feature_index=None, threshold=None, left=None, right=None, *, value=None):\n",
    "    self.feature_index = feature_index\n",
    "    self.threshold = threshold\n",
    "    self.left = left # left node\n",
    "    self.right = right # right node\n",
    "    self.value = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e081ca38-0ec5-4884-acc0-e7902aa7cfbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Tree Building\n",
    "def build_tree(X, y, depth=0, max_depth=10):\n",
    "  \"\"\"Recursively build decision tree\"\"\"\n",
    "  # if we reached the max depth or the node is the last in the set, then we set the leaf value as the most common value in the current set of labels\n",
    "  if depth == max_depth or len(set(y)) == 1:\n",
    "    leaf_value = max(set(y), key=list(y).count) # finds the element in the set y that has the highest count in the list y, key argument specifies a function to apply to each element before making a comparison. So we check what element has the most occurrences first (example 'Apple' could have 2)\n",
    "    return TreeNode(value=leaf_value)\n",
    "  \n",
    "  # find the best split\n",
    "  best_feature_index, best_threshold, best_gain, best_splits = find_best_split(X, y)\n",
    "\n",
    "  # if no split, make it a leaf\n",
    "  if best_gain == 0:\n",
    "    leaf_value = max(set(y), key=list(y).count)\n",
    "    return TreeNode(value=leaf_value)\n",
    "  \n",
    "  # create child nodes of this node\n",
    "  left_X, right_X, left_y, right_y = best_splits\n",
    "  left_child = build_tree(left_X, left_y, depth + 1, max_depth)\n",
    "  right_child = build_tree(right_X, right_y, depth + 1, max_depth)\n",
    "\n",
    "  return TreeNode(feature_index=best_feature_index, threshold=best_threshold, left=left_child, right=right_child)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff9b8d27-9734-4ca2-86d7-eaeb975903f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def print_tree(node, depth=0):\n",
    "  if node.value is not None:\n",
    "    print(f\"{'  ' * depth}Predict: {node.value}\")\n",
    "  else:\n",
    "    print(f\"{'  ' * depth}[X{node.feature_index} <= {node.threshold}]\")\n",
    "    print_tree(node.left, depth + 1)\n",
    "    print_tree(node.right, depth + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18cb4e77-7790-44d5-81f2-7b0255e00031",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X1 <= 1]\n  Predict: Grape\n  [X1 <= 3]\n    [X0 <= Green]\n      Predict: Apple\n      Predict: Lemon\n    Predict: Apple\n"
     ]
    }
   ],
   "source": [
    "# Test with our small example of data\n",
    "X = [row[:2] for row in training_data]  # Features\n",
    "y = [row[2] for row in training_data]   # Labels\n",
    "# X are the features and they look like this:\n",
    "\"\"\" [['Green', 3], ['Yellow', 4], ['Red', 1], ['Red', 1], ['Yellow', 3]] \"\"\"\n",
    "# y are the labels and they look like this:\n",
    "\"\"\" ['Apple', 'Apple', 'Grape', 'Grape', 'Lemon'] \"\"\"\n",
    "\n",
    "# Build the tree\n",
    "tree = build_tree(X, y, max_depth=3)\n",
    "\n",
    "# Print the tree\n",
    "print_tree(tree)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Decision Tree from Scratch",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}