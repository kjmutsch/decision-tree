# decision-tree
Decision tree made from scratch. The algorithm is written recursively in python using the CART algorithm and Gini impurity. I test the algorithm with small simple datasets as well as with the Iris dataset from sklearn.

## Utility Functions

1. **Gini Impurity Calculation**: Measures the quality of a split after the fact
2. **Information Gain Calculation**: Determines the best split before conducting split
3. **Data Splitting**: Splits the features and labels in the dataset up based on a threshold
4. **Tree Node Creation**: Creates the nodes and leaves
5. **Tree Building**: Recursively builds the tree
6. **Prediction**: Makes predictions using the constructed tree
7. **Accuracy**: Tests the model's performance using test data
8. **Tests**: Series of tests to ensure the model works in different cases with different data

